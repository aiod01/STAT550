---
title: "Initial_Analysis"
author: "Nikolas Krstic"
date: "March 14, 2018"
output: html_document
---

```{r}
library(haven)
library(MASS)
library(ordinal)
library(leaps)
```

```{r}
##Data Cleaning
wd = substr(getwd(), 1, nchar(getwd())-4)
MAIN_data = read_sav(paste(wd, "/Data/Data-NFEHRS_revised.sav", sep=""))

#Handle data artifacts
MAIN_data[MAIN_data$num_use==7,]$num_use = NA
MAIN_data[MAIN_data$ED_Level==8,]$ED_Level = 4

#Boolean, which decides whether to combine classes of skill usage or convert them to sums
collapsing=TRUE

if(collapsing){
  MAIN_data$num_use_new = floor(MAIN_data$num_use)
  MAIN_data[MAIN_data$num_use_new %in% c(5),]$num_use_new = 4
  MAIN_data$lit_use_new = floor(MAIN_data$liter_use)
  MAIN_data[MAIN_data$lit_use_new %in% c(5),]$lit_use_new = 4
}else{
  MAIN_data$num_use_new = MAIN_data$num_use*18
  MAIN_data$lit_use_new = MAIN_data$liter_use*12
}
  
hist(MAIN_data$num_use_new)
hist(MAIN_data$lit_use_new)

FactorList = c("pub_priv", "GENDER_R", "ED_Level", "Full_part", "NFE12", "FNFAET12NJR", "FNFAET12JR",
               "lit_use_new", "num_use_new")

MAIN_data[FactorList] = lapply(MAIN_data[FactorList], as.factor)

#Remove variables and make two datasets, one for each response type
Var_Removal = c("AGEG5LFS", "AGEG10LFS", "Mgr", "Mgr_c", "pvlitM", "pvnumM", "FNFE12JR", "FNFAET12", "EMPloyed",
                "FNFAET12JR", "FNFAET12NJR", "NFEHRS")

Lit_data = MAIN_data[!(names(MAIN_data) %in% c("num_use_new", "liter_use", "num_use", Var_Removal))]
Num_data = MAIN_data[!(names(MAIN_data) %in% c("lit_use_new", "liter_use", "num_use", Var_Removal))]

Num_data_clean = na.omit(Num_data)
Lit_data_clean = na.omit(Lit_data)

#Check for Correlations
Subset_Data = MAIN_data[,c("AGE_R","Years_wk","work_flexM","work_lrnM","act_lrn","NFEHRS","pvlitM","pvnumM")]
CorrMatrix = cor(Subset_Data, use="pairwise.complete.obs")

#Eliminated both "FNFAET12NJR" and "FNFAET12JR" since they sum to make NFE12 (causing issues with modelling)
table(as.numeric(MAIN_data$FNFAET12JR)+as.numeric(MAIN_data$FNFAET12NJR), MAIN_data$NFE12)
table(MAIN_data$FNFAET12NJR, MAIN_data$NFE12)
table(MAIN_data$FNFAET12NJR, MAIN_data$FNFAET12JR)

table(MAIN_data$NFEHRS>0, MAIN_data$NFE12)

```

```{r}
##Ordinal Regression (Literacy) (Backward Selection)

Null_Model_1 = clm(num_use_new~1, data=Num_data_clean, Hess=TRUE)
Full_Model_1 = clm(num_use_new~., data=Num_data_clean, Hess=TRUE)

Num_Model = step(Full_Model_1, trace=T, scope=list(upper = Full_Model_1, lower = Null_Model_1))


##Ordinal Regression (Numeracy) (Backward Selection)

Null_Model_2 = clm(lit_use_new~1, data=Lit_data_clean, Hess=TRUE)
Full_Model_2 = clm(lit_use_new~., data=Lit_data_clean, Hess=TRUE)

Liter_Model = step(Full_Model_2, trace=T, scope=list(upper = Full_Model_2, lower = Null_Model_2))


## Exhaustive model selection
#NOTE: Make sure the response variable is the last column in your dataset (otherwise the function will not work)
Exhaustive_OLR_Model_Selection = function(data){
  
  #Number of predictors
  PredNum = ncol(data)-1
  
  #Subtract 1 because last combination is the null model
  AICSet = rep(NA, 2^(PredNum)-1)
  #iterate through every combination of predictors
  for(i in 1:(2^(PredNum)-1)){
    if(i%%100==0){
      print(i)
    }
    #Obtain combination of variables for this 
    VarNums = which(as.numeric(substr(as.character(intToBits(i)), 2,2))[1:PredNum]==1)
    ResponseName = names(data)[ncol(data)]
    PredictorNames = names(data)[VarNums]
    
    M_Formula = as.formula(paste(ResponseName, "~", paste(PredictorNames, collapse="+"), sep=""))
    
    Model = clm(M_Formula, data=data, Hess=TRUE)
    
    AICSet[i] = AIC(Model)
  }
  
  Optim = which.min(AICSet)
  
  VarNums_F = which(as.numeric(substr(as.character(intToBits(Optim)), 2,2))[1:PredNum]==1)
  ResponseName_F = names(data)[ncol(data)]
  PredictorNames_F = names(data)[VarNums_F]
    
  M_Formula_F = as.formula(paste(ResponseName_F, "~", paste(PredictorNames_F, collapse="+"), sep=""))
    
  Model_F = clm(M_Formula_F, data=data, Hess=TRUE)
    
  return(Model_F)
}

#Results seem to suggest the results are the same as backward selection
E_Model_Num = Exhaustive_OLR_Model_Selection(Num_data_clean)
E_Model_Lit = Exhaustive_OLR_Model_Selection(Lit_data_clean)

```
```{r}
#model diagnostics
#check convergence of the model
convergence(E_Model_Lit)
convergence(E_Model_Num)
```
```{r}
#these tests can be viewed as goodness-of-fit tests. With the logit link, nominal_test provides likelihood ratio tests of the proportional odds assumption.
T_Model_Lit<-clm(lit_use_new ~ GENDER_R + AGE_R + ED_Level + Full_part + self_employed + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12,data=Lit_data_clean)
T_Model_Num<-clm(num_use_new ~ AGE_R + ED_Level + Full_part + Years_wk + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12,data=Num_data_clean)
#the proportional oadds assumption test for literacy model
nominal_test(T_Model_Lit)
#the proportional oadds assumption test for numeracy model
nominal_test(T_Model_Num)
```
```{r}
#deviance test for goodness of fit
P_Model_Num<-polr(num_use_new ~ AGE_R + ED_Level + Full_part + Years_wk + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12,data=Num_data_clean)
1-pchisq(deviance(P_Model_Num),df.residual(P_Model_Num))
```
```{r}
#resid function in rms package to check the goodness of fit
```{r}
O_Model_Num<-orm(num_use_new ~ AGE_R + ED_Level + Full_part + Years_wk + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12,data=Num_data_clean,x=TRUE,y=TRUE)
#resid(test1, "partial", pl=TRUE)
#resid(test1,"gof")
#resid(test1, 'score.binary', pl=TRUE) #plot score residuals
#resid(test1,'partial',pl=TRUE)
O_Model_Lit<-orm(lit_use_new ~ GENDER_R + AGE_R + ED_Level + Full_part + self_employed + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12, data=Lit_data_clean,x=TRUE,y=TRUE)
resid(O_Model_Num, 'gof')
resid(O_Model_Lit,'gof')
```
```{r}
#prediction accuracy using 5-fold cross validation
#split the data into 5 datasets
fold1<-Num_data_clean[1:240,]
fold2<-Num_data_clean[241:480,]
fold3<-Num_data_clean[481:720,]
fold4<-Num_data_clean[721:960,]
fold5<-Num_data_clean[961:1207,]
list_fold<-list(fold1,fold2,fold3,fold4,fold5)
names(list_fold)=c("fold1","fold2","fold3","fold4","fold5")
#E_Model_Num
#formula
formula1<-as.formula(num_use_new ~ AGE_R + ED_Level + Full_part + Years_wk + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12)
##construct 5 models
trainset1<-Num_data_clean[-c(1:240),]
trainset2<-Num_data_clean[-c(241:480),]
trainset3<-Num_data_clean[-c(481:720),]
trainset4<-Num_data_clean[-c(721:960),]
trainset5<-Num_data_clean[-c(961:1207),]
mylist<-list(trainset1,trainset2,trainset3,trainset4,trainset5)
names(mylist)=c("trainset1","trainset2","trainset3","trainset4","trainset5")
return_index<-function(x){
	index<-which.max(x)
	return(index)
}
```

```{r}
error<-rep(0,5)
for(i in 1:5){
	model<-clm(formula1, data=mylist[[i]],Hess=TRUE)
	pre_category<-predict(model, newdata=list_fold[[i]][,1:11],type="class")$fit
	true_category<-list_fold[[i]]$num_use_new
  error[i]<-mean(as.vector(true_category)!=as.vector(pre_category))
}
mean(error)
```

```{r}
#5-cross validation for literacy
L_fold1<-Lit_data_clean[1:240,]
L_fold2<-Lit_data_clean[241:480,]
L_fold3<-Lit_data_clean[481:720,]
L_fold4<-Lit_data_clean[721:960,]
L_fold5<-Lit_data_clean[961:1207,]
list_fold_lit<-list(L_fold1,L_fold2,L_fold3,L_fold4,L_fold5)
names(list_fold)=c("fold1","fold2","fold3","fold4","fold5")
#E_Model_Lit
#formula
formula2<-as.formula(lit_use_new ~ GENDER_R + AGE_R + ED_Level + Full_part + self_employed + pub_priv + work_flexM + work_lrnM + act_lrn + NFE12)
##construct 5 models
L_trainset1<-Lit_data_clean[-c(1:240),]
L_trainset2<-Lit_data_clean[-c(241:480),]
L_trainset3<-Lit_data_clean[-c(481:720),]
L_trainset4<-Lit_data_clean[-c(721:960),]
L_trainset5<-Lit_data_clean[-c(961:1207),]
L_mylist<-list(L_trainset1,L_trainset2,L_trainset3,L_trainset4,L_trainset5)
names(mylist)=c("trainset1","trainset2","trainset3","trainset4","trainset5")
```

```{r}
error1<-rep(0,5)
for(i in 1:5){
	model1<-clm(formula2, data=L_mylist[[i]],Hess=TRUE)
	pre_category<-predict(model, newdata=list_fold_lit[[i]][,1:11],type="class")$fit
	true_category<-list_fold_lit[[i]]$lit_use_new
  error1[i]<-mean(as.vector(true_category)!=as.vector(pre_category))
}
mean(error1)
```



```



